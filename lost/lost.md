
# åŸºæœ¬æ¦‚å¿µ

## ðŸŒŸä¸€ã€æ ¸å¿ƒé—®é¢˜ï¼šç¥žç»ç½‘ç»œå¦‚ä½•å­¦ä¼šé¢„æµ‹ï¼Ÿ

ç¥žç»ç½‘ç»œé€šè¿‡**ä¸æ–­è¯•é”™ï¼Œé€æ¸è°ƒæ•´å‚æ•°ï¼ˆæƒé‡ï¼‰æ¥å‡å°‘é¢„æµ‹è¯¯å·®**ã€‚è¿™å°±åƒä½ åœ¨æ‰“ç¯®çƒæ—¶ä¸æ–­è°ƒæ•´æ‰‹çš„åŠ›åº¦å’Œè§’åº¦ï¼Œè®©çƒæ›´å®¹æ˜“è¿›æ¡†ã€‚

---

## ðŸ§ äºŒã€å…³é”®æ¦‚å¿µï¼šæŸå¤±å‡½æ•°ã€æ¢¯åº¦å’Œæ¢¯åº¦ä¸‹é™

### 1. æŸå¤±å‡½æ•°ï¼ˆLoss Functionï¼‰

* è¡¡é‡ç¥žç»ç½‘ç»œé¢„æµ‹å€¼å’ŒçœŸå®žå€¼ä¹‹é—´çš„å·®å¼‚ã€‚
* æ¯”å¦‚ä½ é¢„æµ‹æ˜Žå¤©æ˜¯æ™´å¤©ï¼ˆé¢„æµ‹å€¼=1ï¼‰ï¼Œä½†å®žé™…ä¸Šæ˜¯ä¸‹é›¨ï¼ˆçœŸå®žå€¼=0ï¼‰ï¼Œè¯¯å·®å°±å¤§ã€‚

**å¸¸ç”¨æŸå¤±å‡½æ•°ä¾‹å­**ï¼ˆå‡æ–¹è¯¯å·®ï¼‰ï¼š

$$
L = \frac{1}{2}(y_{\text{é¢„æµ‹}} - y_{\text{çœŸå®ž}})^2
$$

---

### 2. æ¢¯åº¦ï¼ˆGradientï¼‰

* æ¢¯åº¦å°±æ˜¯å¯¼æ•°ï¼Œè¡¨ç¤ºæŸå¤±å‡½æ•°å¯¹æŸä¸ªå‚æ•°çš„â€œå˜åŒ–çŽ‡â€ã€‚
* å¦‚æžœä½ æŠŠæŸå¤±å‡½æ•°ç”»æˆä¸€åº§å±±ï¼Œæ¢¯åº¦å°±æ˜¯ä½ åœ¨å±±ä¸Šå½“å‰ç‚¹å¾€ä¸‹æœ€å¿«çš„æ–¹å‘ã€‚

---

### 3. æ¢¯åº¦ä¸‹é™æ³•ï¼ˆGradient Descentï¼‰

* ä¸€ç§**ä¸æ–­å‘â€œè¯¯å·®æœ€å°çš„æ–¹å‘â€èµ°çš„ç­–ç•¥**ã€‚
* æ¯æ¬¡éƒ½ç”¨å½“å‰çš„æ¢¯åº¦æ¥â€œè°ƒæ•´å‚æ•°â€ï¼Œè®©æŸå¤±è¶Šæ¥è¶Šå°ã€‚

$$
w = w - \eta \cdot \frac{\partial L}{\partial w}
$$

* $w$ï¼šå½“å‰å‚æ•°ï¼ˆæƒé‡ï¼‰
* $\eta$ï¼šå­¦ä¹ çŽ‡ï¼ˆæŽ§åˆ¶æ­¥é•¿å¤§å°ï¼‰
* $\frac{\partial L}{\partial w}$ï¼šæ¢¯åº¦

---



## ðŸ§ªä¸‰ã€ä»£ç æ¼”ç¤ºï¼šæœ€ç®€å•çš„ä¸€ç»´çº¿æ€§å›žå½’

æˆ‘ä»¬ç”¨Pythonå’Œ`matplotlib`ç”»å›¾ï¼Œæ¼”ç¤ºç¥žç»ç½‘ç»œæ˜¯æ€Žä¹ˆå­¦ä¹ ä¸€ä¸ªç®€å•å…³ç³»ï¼š
â€œç»™ä½ ä¸€ä¸ªxï¼Œé¢„æµ‹y=2xâ€ã€‚

### ðŸ”§ä»£ç ï¼ˆPythonï¼‰

```python
import numpy as np
import matplotlib.pyplot as plt

# ç›®æ ‡å‡½æ•°ï¼šy = 2x
x = np.array([1, 2, 3, 4])
y_true = 2 * x

# åˆå§‹åŒ–å‚æ•° wï¼ˆé¢„æµ‹çš„ä¹˜æ•°ï¼‰ï¼Œå­¦ä¹ çŽ‡
w = 0.1
learning_rate = 0.01

loss_history = []

# è®­ç»ƒ100è½®
for epoch in range(100):
    y_pred = w * x
    loss = np.mean((y_pred - y_true)**2)  # å‡æ–¹è¯¯å·®
    grad = np.mean(2 * x * (y_pred - y_true))  # å¯¹wçš„å¯¼æ•°
    
    w -= learning_rate * grad  # æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°
    
    loss_history.append(loss)

# ç”»å‡ºæŸå¤±æ›²çº¿
plt.plot(loss_history)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Loss over time (æ¢¯åº¦ä¸‹é™å‡å°‘è¯¯å·®)")
plt.grid(True)
plt.show()
```

ðŸ‘†è¿™ä¸ªç¨‹åºå¯ä»¥æ¸…æ¥šåœ°æ˜¾ç¤ºï¼Œæ¯è½®è®­ç»ƒåŽæŸå¤±ï¼ˆè¯¯å·®ï¼‰å¦‚ä½•é€æ¸ä¸‹é™ã€‚



# å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æŸå¤±å‡½æ•°çš„å‡½æ•°æ›²çº¿æ˜¯æ€Žæ ·çš„**ï¼Œå¹¶è§£é‡Šå®ƒçš„å½¢çŠ¶å’Œå«ä¹‰ã€‚



## ðŸ“Œ ä¸€ã€å‡æ–¹è¯¯å·®çš„æ•°å­¦å®šä¹‰ï¼ˆå•ä¸ªæ ·æœ¬ï¼‰

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªéžå¸¸ç®€å•çš„æ¨¡åž‹ï¼š

* è¾“å…¥ $x$
* æ¨¡åž‹çš„é¢„æµ‹æ˜¯ $\hat{y} = wx$ï¼Œå…¶ä¸­ $w$ æ˜¯æƒé‡
* çœŸå®žå€¼æ˜¯ $y$

\*\*å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰\*\*çš„å®šä¹‰æ˜¯ï¼š

$$
L(w) = \frac{1}{2}(wx - y)^2
$$

è¿™ä¸ªå‡½æ•°çš„è‡ªå˜é‡æ˜¯ **$w$**ï¼ŒæŸå¤±å€¼ $L(w)$ éšç€ $w$ çš„ä¸åŒè€Œå˜åŒ–ã€‚

---

## ðŸ“ˆ äºŒã€å‡½æ•°æ›²çº¿çš„å½¢çŠ¶

### â–¶ æ•°å­¦ä¸Šè¿™æ˜¯ä¸€ä¸ª**æŠ›ç‰©çº¿**ï¼š

* å®ƒçš„æœ€ä½Žç‚¹ï¼ˆè°·åº•ï¼‰æ˜¯å½“é¢„æµ‹å€¼ç­‰äºŽçœŸå®žå€¼æ—¶ï¼Œä¹Ÿå°±æ˜¯è¯¯å·®æœ€å°æ—¶ã€‚
* å½¢çŠ¶å¯¹ç§°ï¼Œå¼€å£å‘ä¸Šã€‚
* æ›²çº¿è¶Šé™¡ï¼Œè¡¨ç¤ºè¯¯å·®å¯¹å‚æ•°çš„å˜åŒ–è¶Šæ•æ„Ÿã€‚

### âœ… ä¸¾ä¾‹ï¼š

å‡è®¾ $x = 2$ï¼Œ$y = 4$ï¼ˆç›®æ ‡å‡½æ•°æ˜¯ $y = 2x$ï¼‰

$$
L(w) = \frac{1}{2}(2w - 4)^2
$$

æˆ‘ä»¬æŠŠå®ƒç”»å‡ºæ¥çœ‹çœ‹ï¼š

---

## ðŸ§ª ä¸‰ã€ä»£ç ï¼šç”»å‡ºå‡æ–¹è¯¯å·®çš„å‡½æ•°æ›²çº¿

```python
import numpy as np
import matplotlib.pyplot as plt

# å‡è®¾ x=2, y=4
x = 2
y = 4

# åœ¨ä¸åŒçš„ w å–å€¼ä¸‹è®¡ç®—æŸå¤± L(w)
w_values = np.linspace(0, 4, 100)
loss_values = 0.5 * (x * w_values - y)**2

plt.plot(w_values, loss_values)
plt.xlabel("w")
plt.ylabel("Loss")
plt.title("å‡æ–¹è¯¯å·® MSE æŸå¤±å‡½æ•°æ›²çº¿")
plt.grid(True)
plt.show()
```

---

## ðŸ” å››ã€å›¾å½¢è§£è¯»ï¼ˆä½ å°†çœ‹åˆ°ï¼‰

* æ›²çº¿æ˜¯ä¸€ä¸ª **Uåž‹** çš„æŠ›ç‰©çº¿
* æœ€ä½Žç‚¹åœ¨ $w = 2$ï¼Œæ­¤æ—¶ $wx = 4$ï¼Œé¢„æµ‹å€¼ç­‰äºŽçœŸå®žå€¼ï¼ŒæŸå¤±æœ€å°ä¸º 0
* è¶Šè¿œç¦» $w = 2$ï¼Œè¯¯å·®è¶Šå¤§ï¼ŒæŸå¤±å€¼ä¸Šå‡å¾ˆå¿«

---

| æ¦‚å¿µ   | å«ä¹‰è¯´æ˜Ž                   |
| ---- | ---------------------- |
| å‡æ–¹è¯¯å·® | ç”¨äºŽè¡¡é‡é¢„æµ‹å€¼å’ŒçœŸå®žå€¼ä¹‹é—´çš„å·®å¼‚       |
| æ›²çº¿å½¢çŠ¶ | æŠ›ç‰©çº¿ï¼Œå¼€å£å‘ä¸Š               |
| æœ€å°å€¼ç‚¹ | å½“é¢„æµ‹å®Œå…¨æ­£ç¡®æ—¶ï¼ŒæŸå¤±ä¸º 0         |
| æ¢¯åº¦ä¸‹é™ | æ²¿ç€æ›²çº¿çš„æ–œçŽ‡æ–¹å‘ï¼ˆå¯¼æ•°ï¼‰ä¸€æ­¥æ­¥å‘æœ€ä½Žç‚¹é è¿‘ |


---

## ðŸ” ä¸€ã€å¸¸è§æŸå¤±å‡½æ•°çš„å½¢çŠ¶å¯¹æ¯”

| æŸå¤±å‡½æ•°              | æ›²çº¿å¤§è‡´å½¢çŠ¶   | æ˜¯å¦å…‰æ»‘    | å…¸åž‹åº”ç”¨         |
| ----------------- | -------- | ------- | ------------ |
| **å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**     | æŠ›ç‰©çº¿      | âœ… å¹³æ»‘    | å›žå½’           |
| **ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰**     | V åž‹      | âŒ ä¸å¯å¯¼äºŽ0 | å›žå½’           |
| **Huber æŸå¤±**      | è¿‘ä¼¼æŠ›ç‰©çº¿+Våž‹ | âœ… åˆ†æ®µå…‰æ»‘  | æŠ—å¼‚å¸¸ç‚¹å›žå½’       |
| **äº¤å‰ç†µæŸå¤±**         | Såž‹æˆ–å¯¹æ•°åž‹   | âœ… å¹³æ»‘    | åˆ†ç±»ï¼ˆå¦‚Softmaxï¼‰ |
| **Hinge æŸå¤±**ï¼ˆSVMï¼‰ | æŠ˜çº¿       | âŒ ä¸å…‰æ»‘   | åˆ†ç±»ï¼ˆæ”¯æŒå‘é‡æœºï¼‰    |

---

## ðŸ“ˆ äºŒã€å›¾åƒå¯¹æ¯”ï¼ˆæè¿°ï¼‰

1. **MSEï¼ˆæŠ›ç‰©çº¿ï¼‰**ï¼š

   $$
   L = \frac{1}{2}(y_{\text{pred}} - y_{\text{true}})^2
   $$

   * ä¼˜ç‚¹ï¼šå¹³æ»‘ï¼Œå¯¼æ•°æ˜“ç®—
   * ç¼ºç‚¹ï¼šå¯¹å¼‚å¸¸å€¼æ•æ„Ÿ

2. **MAEï¼ˆç»å¯¹å€¼ï¼‰**ï¼š

   $$
   L = |y_{\text{pred}} - y_{\text{true}}|
   $$

   * æ˜¯ä¸€ä¸ª **Våž‹** å‡½æ•°
   * å¯¼æ•°åœ¨ 0 å¤„ä¸è¿žç»­ï¼Œä¸é€‚åˆæŸäº›æ¢¯åº¦æ–¹æ³•

3. **äº¤å‰ç†µï¼ˆåˆ†ç±»å¸¸ç”¨ï¼‰**ï¼š

   $$
   L = -y \log(\hat{y}) - (1 - y)\log(1 - \hat{y})
   $$

   * æ›²çº¿åœ¨é è¿‘ 0 æˆ– 1 æ—¶é™¡å³­ï¼Œæœ‰åŠ©äºŽåˆ†ç±»æ˜Žç¡®åŒ–
   * å¯¹äºŽâ€œç½®ä¿¡åº¦é”™è¯¯â€çš„é¢„æµ‹æƒ©ç½šå¾ˆå¤§

4. **Hinge æŸå¤±ï¼ˆSVMï¼‰**ï¼š

   $$
   L = \max(0, 1 - y \cdot \hat{y})
   $$

   * å¦‚æžœé¢„æµ‹æ­£ç¡®ä¸”â€œæœ‰ marginâ€ï¼ŒæŸå¤±ä¸º 0
   * å¦åˆ™çº¿æ€§æƒ©ç½š

---

## ðŸ§  ä¸‰ã€æ€»ç»“ï¼šæ›²çº¿æ˜¯å¦â€œå¥½â€çœ‹ä»€ä¹ˆ

| ç‰¹æ€§      | å½±å“                       |
| ------- | ------------------------ |
| æ˜¯å¦å…‰æ»‘    | å½±å“æ¢¯åº¦è®¡ç®—ï¼ˆå…‰æ»‘å‡½æ•°æ›´é€‚åˆæ¢¯åº¦ä¸‹é™ï¼‰      |
| æ˜¯å¦å•å³°ï¼ˆå‡¸ï¼‰ | æ›´å®¹æ˜“ä¼˜åŒ–ï¼Œä¿è¯æ‰¾åˆ°æœ€ä¼˜è§£            |
| æ˜¯å¦é²æ£’    | æ˜¯å¦å¯¹å¼‚å¸¸å€¼æ•æ„Ÿï¼ˆå¦‚ MAEã€Huberæ›´é²æ£’ï¼‰ |
| é€‚ç”¨ä»»åŠ¡    | å›žå½’ vs åˆ†ç±»ï¼Œä¸åŒä»»åŠ¡é€‚åˆä¸åŒçš„æŸå¤±å‡½æ•°   |

---


# é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°å’ŒæŸå¤±å‡½æ•°

---

## âœ… ä¸€ã€é€‰æ‹©çš„æ ¸å¿ƒæ€è·¯ï¼š

| **é€‰æ‹©æ¿€æ´»å‡½æ•°å’ŒæŸå¤±å‡½æ•°çš„ä¾æ®** |
| ------------------ |
| ä»»åŠ¡ç±»åž‹ï¼ˆåˆ†ç±» vs å›žå½’ï¼‰     |
| è¾“å‡ºå€¼çš„å–å€¼èŒƒå›´           |
| æ˜¯å¦å­˜åœ¨ç¦»ç¾¤ç‚¹ï¼ˆå¼‚å¸¸å€¼ï¼‰       |
| æ˜¯å¦å¯¹æ¢¯åº¦æ•æ„Ÿæˆ–æ¢¯åº¦æ¶ˆå¤±       |

---

## ðŸ” äºŒã€å¸¸è§åœºæ™¯å¯¹ç…§è¡¨ï¼ˆä»»åŠ¡ â†’ æ¿€æ´»å‡½æ•° + æŸå¤±å‡½æ•°ï¼‰

| åœºæ™¯           | è¾“å‡ºå±‚æ¿€æ´»å‡½æ•°            | æŸå¤±å‡½æ•°                            | è¯´æ˜Ž                     |
| ------------ | ------------------ | ------------------------------- | ---------------------- |
| **äºŒåˆ†ç±»**      | `Sigmoid`          | `Binary Cross-Entropy`          | è¾“å‡ºå€¼èŒƒå›´ \[0,1]ï¼Œé€‚åˆåˆ¤æ–­â€œæ˜¯/å¦â€ |
| **å¤šåˆ†ç±»ï¼ˆç‹¬ç«‹ç±»ï¼‰** | `Softmax`          | `Categorical Cross-Entropy`     | å¤šä¸ªäº’æ–¥ç±»åˆ«ï¼Œè¾“å‡ºä¸ºæ¦‚çŽ‡åˆ†å¸ƒ         |
| **å›žå½’ï¼ˆè¿žç»­è¾“å‡ºï¼‰** | `æ— ` æˆ– `ReLU`       | `MSE` æˆ– `MAE`                   | è¾“å‡ºä¸ºå®žæ•°ï¼Œæ— éœ€å½’ä¸€åŒ–            |
| **æœ‰å¼‚å¸¸å€¼çš„å›žå½’**  | `æ— ` æˆ– `ReLU`       | `Huber Loss`                    | HuberæŸå¤±å¯¹ç¦»ç¾¤å€¼ä¸æ•æ„Ÿ         |
| **ç”Ÿæˆæ¨¡åž‹è¾“å‡ºå›¾ç‰‡** | `Tanh` æˆ– `Sigmoid` | `MSE`ã€`L1` æˆ– `Adversarial Loss` | è¾“å‡ºå›¾åƒåƒç´ åœ¨\[-1,1]æˆ–\[0,1]  |
| **å¼ºåŒ–å­¦ä¹ è¾“å‡ºQå€¼** | `æ— `                | `Smooth L1`ã€`Huber`             | é¿å…æ¢¯åº¦çˆ†ç‚¸ï¼Œç¨³å¥è®­ç»ƒ            |

---

## ðŸ”§ ä¸‰ã€å…·ä½“å‡½æ•°çš„é€‰æ‹©ç†ç”±

### ðŸ”¹ æ¿€æ´»å‡½æ•°ï¼š

| å‡½æ•°         | é€‚ç”¨æƒ…å†µ          | ç‰¹ç‚¹                     |
| ---------- | ------------- | ---------------------- |
| ReLU       | éšè—å±‚é€šç”¨ï¼Œè®­ç»ƒå¿«     | éžçº¿æ€§ï¼Œæ­£å€¼ä¿ç•™ï¼Œè´Ÿå€¼ä¸º0ï¼Œå¯èƒ½â€œæ­»ç¥žç»å…ƒâ€ |
| Leaky ReLU | æ”¹è¿›ReLUï¼Œé¿å…æ­»ç¥žç»å…ƒ | è´Ÿå€¼ä¹Ÿæœ‰å°æ–œçŽ‡                |
| Sigmoid    | äºŒåˆ†ç±»è¾“å‡ºå±‚        | è¾“å‡ºåœ¨0\~1ï¼Œå®¹æ˜“æ¢¯åº¦æ¶ˆå¤±         |
| Tanh       | ç”¨äºŽå›¾åƒã€ç”Ÿæˆæ¨¡åž‹ä¸­    | è¾“å‡ºåœ¨-1\~1ï¼Œ0ä¸­å¿ƒ           |
| Softmax    | å¤šåˆ†ç±»è¾“å‡ºå±‚        | è¾“å‡ºå„ç±»æ¦‚çŽ‡å’Œä¸º1              |

---

### ðŸ”¸ æŸå¤±å‡½æ•°ï¼š

| å‡½æ•°                        | é€‚ç”¨ä»»åŠ¡ | ç‰¹ç‚¹                |
| ------------------------- | ---- | ----------------- |
| MSE                       | å›žå½’   | å¯¹å¤§è¯¯å·®æ•æ„Ÿï¼Œæƒ©ç½šå¤§        |
| MAE                       | å›žå½’   | å¯¹å¼‚å¸¸å€¼ç¨³å¥            |
| Huber Loss                | å›žå½’   | ç»¼åˆ MSE å’Œ MAE çš„ä¼˜ç‚¹  |
| Binary Cross Entropy      | äºŒåˆ†ç±»  | é¢„æµ‹æ¦‚çŽ‡æ˜¯å¦è´´è¿‘çœŸå®žæ ‡ç­¾      |
| Categorical Cross Entropy | å¤šåˆ†ç±»  | ç”¨ softmax è¾“å‡ºï¼Œé…åˆæ¦‚çŽ‡ |

---

## ðŸ“˜ å››ã€å®žä¾‹æ¼”ç¤ºï¼ˆç”¨ä¾‹ï¼‰

### âœ… ä¾‹ 1ï¼šå›¾åƒåˆ†ç±»ï¼ˆçŒ« vs ç‹—ï¼‰

* è¾“å…¥ï¼šå›¾ç‰‡
* è¾“å‡ºï¼šæ˜¯çŒ«ï¼ˆ1ï¼‰è¿˜æ˜¯ç‹—ï¼ˆ0ï¼‰

```python
æ¿€æ´»å‡½æ•°ï¼šSigmoid
æŸå¤±å‡½æ•°ï¼šBinary Cross Entropy
```

---

### âœ… ä¾‹ 2ï¼šæˆ¿ä»·é¢„æµ‹

* è¾“å…¥ï¼šé¢ç§¯ã€ä½ç½®ç­‰ç‰¹å¾
* è¾“å‡ºï¼šæˆ¿ä»·ï¼ˆè¿žç»­æ•°å€¼ï¼‰

```python
æ¿€æ´»å‡½æ•°ï¼šNoneï¼ˆè¾“å‡ºå±‚ä¸ºçº¿æ€§ï¼‰
æŸå¤±å‡½æ•°ï¼šMSEï¼ˆæˆ– Huberï¼‰
```

---

### âœ… ä¾‹ 3ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«ï¼ˆ0\~9ï¼‰

* è¾“å…¥ï¼š28Ã—28ç°åº¦å›¾åƒ
* è¾“å‡ºï¼š10ä¸ªç±»åˆ«ä¹‹ä¸€

```python
æ¿€æ´»å‡½æ•°ï¼šSoftmaxï¼ˆè¾“å‡ºå±‚ï¼‰
æŸå¤±å‡½æ•°ï¼šCategorical Cross Entropy
```

---

## âœ… äº”ã€æ€»ç»“ï¼šé€‰æ‹©æŒ‡å—ï¼ˆå£è¯€ï¼‰

> **åˆ†ç±»é€‰äº¤å‰ç†µï¼Œè¾“å‡ºç”¨æ¿€æ´»é… Sigmoid æˆ– Softmaxï¼›
> å›žå½’é€‰MSEï¼Œå¼‚å¸¸ç‚¹å¤šå°±æ¢ Huberï¼›
> ä¸­é—´å±‚ç”¨ ReLUï¼Œè¾“å‡ºå±‚çœ‹ä»»åŠ¡ã€‚**

---

